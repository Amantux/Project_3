knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(openxlsx)
library(dplyr)
library(zoo)
library(varhandle)
library(rvest)
library(tidyverse)
library(openxlsx)
library(dplyr)
library(zoo)
library(varhandle)
library(rvest)
library(RSelenium)
if (Fresh_Computes && Fresh_Data){
remDr <- RSelenium::remoteDriver(remoteServerAddr = "localhost",
port = 4444,
browserName = "chrome")
remDr$open()
}
Fresh_Data <- FALSE #This will refresh data (Not using caching from my git)
Fresh_Computes <- TRUE  #Uses docker to pull and augment data, requires the Selenium Instance
Dev_Checks <- FALSE #Various Extra Print statements that make debugging easier
if (Fresh_Computes && Fresh_Data){
remDr <- RSelenium::remoteDriver(remoteServerAddr = "localhost",
port = 4444,
browserName = "chrome")
remDr$open()
}
library(tidyverse)
library(openxlsx)
library(dplyr)
library(zoo)
library(varhandle)
library(rvest)
library(RSelenium)
library(xml2)
url <- "https://www.indeed.com/jobs?q=data scientist&l=Cambridge%2C MA"
page <- xml2::read_html(url)
url <- "https://www.indeed.com/jobs?q=data+scientist&l=Cambridge%2C+MA"
page <- xml2::read_html(url)
library(tidyverse)
library(openxlsx)
library(dplyr)
library(zoo)
library(varhandle)
library(rvest)
library(RSelenium)
library(xml2)
library(Rcrawler)
install.packages("Rcrawler")
library(tidyverse)
library(openxlsx)
library(dplyr)
library(zoo)
library(varhandle)
library(rvest)
library(RSelenium)
library(xml2)
library(Rcrawler)
Rcrawler(Website = "https://www.indeed.com/jobs?q=data%20scientist&l=Cambridge%252C%20MA", no_cores = 4, no_conn = 4, ExtractXpathPat = c("/html/body/table[2]/tbody/tr/td/table/tbody/tr/td[1]/div[5]/div/a[1]/div[1]/div/div[1]/div/table[1]/tbody/tr/td/div[1]/h2","/html/body/table[2]/tbody/tr/td/table/tbody/tr/td[1]/div[5]/div/a[1]/div[1]/div/div[1]/div/table[1]/tbody/tr/td/div[2]/div"), PatternsNames = c("Title","Location"))
Rcrawler(Website = "https://www.indeed.com/jobs?q=data%20scientist&l=Cambridge%252C%20MA", no_cores = 4, no_conn = 4, ExtractXpathPat = c("/html/body/table[2]/tbody/tr/td/table/tbody/tr/td[1]/div[5]/div/a[1]/div[1]/div/div[1]/div/table[1]/tbody/tr/td/div[1]/h2","/html/body/table[2]/tbody/tr/td/table/tbody/tr/td[1]/div[5]/div/a[1]/div[1]/div/div[1]/div/table[1]/tbody/tr/td/div[2]/div"), PatternsNames = c("Title","Location"), MaxDepth=1)
Rcrawler(Website = "https://www.indeed.com/jobs?q=data%20scientist&l=Cambridge%252C%20MA", no_cores = 4, no_conn = 4, ExtractXpathPat = c("/html/body/table[2]/tbody/tr/td/table/tbody/tr/td[1]/div[5]/div/a[1]/div[1]/div/div[1]/div/table[1]/tbody/tr/td/div[1]/h2","/html/body/table[2]/tbody/tr/td/table/tbody/tr/td[1]/div[5]/div/a[1]/div[1]/div/div[1]/div/table[1]/tbody/tr/td/div[2]/div"), PatternsNames = c("Title","Location"), MaxDepth=1)
Rcrawler(Website = "https://www.indeed.com/jobs?q=data%20scientist&l=Cambridge%252C%20MA", no_cores = 4, no_conn = 4, ExtractCSSPat = c(".jobTitle",".companyLocation"), PatternsNames = c("Title","Location"), ManyPerPattern = TRUE, MaxDepth=1)
Rcrawler(Website = "https://www.indeed.com/jobs?q=data%20scientist&l=Cambridge%252C%20MA", no_cores = 4, no_conn = 4, ExtractCSSPat = c(".jobTitle",".companyLocation", "companyName"), PatternsNames = c("Title","Location", "Company Name"), ManyPerPattern = TRUE, MaxDepth=1)
Rcrawler(Website = "https://www.indeed.com/jobs?q=data%20scientist&l=Cambridge%252C%20MA", no_cores = 4, no_conn = 4, ExtractCSSPat = c(".jobTitle",".companyLocation", "companyName"), PatternsNames = c("Title","Location", "Company Name"), ManyPerPattern = TRUE, MaxDepth=1)
Rcrawler(Website = "https://www.indeed.com/jobs?q=data%20scientist&l=Cambridge%252C%20MA", no_cores = 4, no_conn = 4, ExtractCSSPat = c(".jobTitle",".companyLocation", ".companyName"), PatternsNames = c("Title","Location", "Company Name"), ManyPerPattern = TRUE, MaxDepth=1)
ListProjects()
ListProjects()
INDEX
Data<-ContentScraper(Url = "https://www.indeed.com/jobs?q=data%20scientist&l=Cambridge%252C%20MA", ExtractCSSPat = c(".jobTitle",".companyLocation", ".companyName"), PatternsNames = c("Title","Location", "Company Name"))
Data<-ContentScraper(Url = "https://www.indeed.com/jobs?q=data%20scientist&l=Cambridge%252C%20MA", ExtractCSSPat = c(".jobTitle",".companyLocation", ".companyName"))
Data<-ContentScraper(Url = "https://www.indeed.com/jobs?q=data%20scientist&l=Cambridge%252C%20MA", ExtractCSSPat = c(".jobTitle",".companyLocation", ".companyName"))
Data<-ContentScraper(Url = "https://www.indeed.com/jobs?q=data%20scientist&l=Cambridge%252C%20MA", CSSPat = c(".jobTitle",".companyLocation", ".companyName"))
Data<-ContentScraper(Url = "https://www.indeed.com/jobs?q=data%20scientist&l=Cambridge%252C%20MA", CSSPaterns = c(".jobTitle",".companyLocation", ".companyName"))
Data<-ContentScraper(Url = "http://glofile.com/index.php/2017/06/08/athletisme-m-a-rome/", CssPatterns = c(".entry-title",".entry-content"))
#Data<-ContentScraper(Url = "https://www.indeed.com/jobs?q=data%20scientist&l=Cambridge%252C%20MA", CSSPaterns = c(".jobTitle",".companyLocation", ".companyName"))
Data<-ContentScraper(Url = "https://www.indeed.com/jobs?q=data%20scientist&l=Cambridge%252C%20MA", CssPatterns = c(".jobTitle",".companyLocation"))
#Data<-ContentScraper(Url = "https://www.indeed.com/jobs?q=data%20scientist&l=Cambridge%252C%20MA", CSSPaterns = c(".jobTitle",".companyLocation", ".companyName"))
Data<-ContentScraper(Url = "https://www.indeed.com/jobs?q=data%20scientist&l=Cambridge%252C%20MA", CssPatterns = c("jobTitle","companyLocation"))
#Data<-ContentScraper(Url = "https://www.indeed.com/jobs?q=data%20scientist&l=Cambridge%252C%20MA", CSSPaterns = c(".jobTitle",".companyLocation", ".companyName"))
Data<-ContentScraper(Url = "https://www.indeed.com/jobs?q=data%20scientist&l=Cambridge%252C%20MA", CssPatterns = c("jobTitle","companyLocation"))
Data
#Data<-ContentScraper(Url = "https://www.indeed.com/jobs?q=data%20scientist&l=Cambridge%252C%20MA", CSSPaterns = c(".jobTitle",".companyLocation", ".companyName"))
Data<-ContentScraper(Url = "https://www.indeed.com/jobs?q=data%20scientist&l=Cambridge%2C%20MA&vjk=f829f300198f1fc8", CssPatterns = c("jobTitle","companyLocation"))
Data
#Data<-ContentScraper(Url = "https://www.indeed.com/jobs?q=data%20scientist&l=Cambridge%252C%20MA", CSSPaterns = c(".jobTitle",".companyLocation", ".companyName"))
Data<-ContentScraper(Url = "https://www.indeed.com/jobs?q=data%20scientist&l=Cambridge%2C%20MA&vjk=f829f300198f1fc8", CssPatterns = c("jobTitle","companyLocation"))
Data
#Data<-ContentScraper(Url = "https://www.indeed.com/jobs?q=data%20scientist&l=Cambridge%252C%20MA", CSSPaterns = c(".jobTitle",".companyLocation", ".companyName"))
Data<-ContentScraper(Url = "https://www.indeed.com/jobs?q=data%20scientist&l=Cambridge%2C%20MA&vjk=f829f300198f1fc8", CssPatterns = c(".jobTitle",".companyLocation"))
Data
#Data<-ContentScraper(Url = "https://www.indeed.com/jobs?q=data%20scientist&l=Cambridge%252C%20MA", CSSPaterns = c(".jobTitle",".companyLocation", ".companyName"))
Rcrawler(Website = "https://www.indeed.com/jobs?q=data%20scientist&l=Cambridge%252C%20MA", no_cores = 4, no_conn = 4, ExtractCSSPat = c(".jobTitle",".companyLocation", ".companyName"), PatternsNames = c("Title","Location", "Company Name"), crawlUrlfilter = c("/rc/","start="), dataUrlfilter = "/rc/", crawlZoneCSSPat = "td#resultsCol",    ManyPerPattern = TRUE, MaxDepth=1)
Rcrawler(Website = "https://www.indeed.com/jobs?q=data%20scientist&l=Cambridge%2C%20MA", no_cores = 4 , no_conn = 4,
crawlUrlfilter = c("/rc/","start="), dataUrlfilter = "/rc/",
crawlZoneCSSPat = "td#resultsCol"
)
Rcrawler(Website = "https://www.indeed.com/jobs?q=data%20scientist&l=Cambridge%2C%20MA", no_cores = 4 , no_conn = 4,
crawlUrlfilter = c("/rc/","start="), dataUrlfilter = "/rc/",
crawlZoneCSSPat = "td#resultsCol",
ManyPerPattern = TRUE, MaxDepth=1
)
Rcrawler(Website = "https://www.indeed.com/jobs?q=data%20scientist&l=Cambridge%2C%20MA", no_cores = 4 , no_conn = 4,
crawlUrlfilter = c("/rc/","start="), dataUrlfilter = "/rc/",
crawlZoneCSSPat = "td#resultsCol",
ManyPerPattern = TRUE, MaxDepth=1
)
Data<-ContentScraper(Url = "https://www.indeed.com/jobs?q=data%20scientist&l=Cambridge%2C%20MA&vjk=f829f300198f1fc8", CssPatterns = c(".jobTitle",".companyLocation"))
Data
#Data<-ContentScraper(Url = "https://www.indeed.com/jobs?q=data%20scientist&l=Cambridge%252C%20MA", CSSPaterns = c(".jobTitle",".companyLocation", ".companyName"))
Rcrawler(Website = "https://www.indeed.com/jobs?q=data%20scientist&l=Cambridge%252C%20MA", no_cores = 4, no_conn = 4, ExtractCSSPat = c(".jobTitle",".companyLocation", ".companyName"), PatternsNames = c("Title","Location", "Company Name"), crawlUrlfilter = c("/rc/","start="), dataUrlfilter = "/rc/", crawlZoneCSSPat = "td#resultsCol",    ManyPerPattern = TRUE, MaxDepth=1)
Rcrawler(Website = "https://www.indeed.com/jobs?q=data%20scientist&l=Cambridge%252C%20MA", no_cores = 4, no_conn = 4, ExtractCSSPat = c(".jobTitle",".companyLocation", ".companyName"), PatternsNames = c("Title","Location", "Company Name"), crawlUrlfilter = c("/rc/","start="), dataUrlfilter = "/rc/", crawlZoneCSSPat = "td#resultsCol",    ManyPerPattern = TRUE, MaxDepth=1)
ListProjects()
INDEX
ListProjects()
INDEX
ListProjects()
INDEX
Rcrawler(Website = "https://www.indeed.com/jobs?q=data%20scientist&l=Cambridge%252C%20MA", no_cores = 4, no_conn = 4, ExtractCSSPat = c(".jobTitle",".companyLocation", ".companyName"), PatternsNames = c("Title","Location", "Company Name"), ManyPerPattern = TRUE, MaxDepth=1)
Rcrawler(Website = "https://www.indeed.com/jobs?q=data%20scientist&l=Cambridge%252C%20MA", no_cores = 4, no_conn = 4, ExtractCSSPat = c(".jobTitle",".companyLocation", ".companyName"), PatternsNames = c("Title","Location", "Company Name"), ManyPerPattern = TRUE, MaxDepth=1)
Rcrawler(Website = "https://www.indeed.com/jobs?q=data%20scientist&l=Cambridge%20MA", no_cores = 4, no_conn = 4, ExtractCSSPat = c(".jobTitle",".companyLocation", ".companyName"), PatternsNames = c("Title","Location", "Company Name"), ManyPerPattern = TRUE, MaxDepth=1)
ListProjects()
INDEX
url.data <- "https://raw.githubusercontent.com/jamhall/programming-languages-csv/master/languages.csv"
raw <- read.csv(url(url.data), header = TRUE,)
url.data <- "https://raw.githubusercontent.com/jamhall/programming-languages-csv/master/languages.csv"
raw <- read.csv(url(url.data), header = TRUE,)
raw
url.data <- "https://raw.githubusercontent.com/jamhall/programming-languages-csv/master/languages.csv"
raw <- read.csv(url(url.data), header = TRUE,)
raw$name
url.data <- "https://raw.githubusercontent.com/jamhall/programming-languages-csv/master/languages.csv"
raw <- read.csv(url(url.data), header = TRUE,)
programming_list <- raw$name
process_programming_list <- function(text_block, list_allowed) {
list_allowed[text_block %in% list_allowed]
}
process_programming_list("C++ Python Test",programming_list)
library(Rcrawler)
library(fuzzywuzzyR)
install.packages("fuzzywuzzyR")
library(Rcrawler)
library(fuzzywuzzyR)
vec = c('Frodo Baggins', 'Tom Sawyer', 'Bilbo Baggin')
str1 = 'Fra Bagg'
GetCloseMatches(string = str1, sequence_strings = vec, n = 2L, cutoff = 0.6)
vec = c('Frodo Baggins', 'Tom Sawyer', 'Bilbo Baggin')
str1 = 'Fra Bagg'
GetCloseMatches(string = str1, sequence_strings = vec, n = 2L, cutoff = 0.6)
library(Rcrawler)
library(fuzzywuzzyR)
vec = c('Frodo Baggins', 'Tom Sawyer', 'Bilbo Baggin')
str1 = 'Fra Bagg'
GetCloseMatches(string = str1, sequence_strings = vec, n = 2L, cutoff = 0.6)
vec <- c('Frodo Baggins', 'Tom Sawyer', 'Bilbo Baggin')
str1 <- 'Fra Bagg'
GetCloseMatches(string = str1, sequence_strings = vec, n = 2L, cutoff = 0.6)
if (reticulate::py_available(initialize = FALSE)) {
if (check_availability()) {
library(fuzzywuzzyR)
vec = c('Frodo Baggins', 'Tom Sawyer', 'Bilbo Baggin')
str1 = 'Fra Bagg'
GetCloseMatches(string = str1, sequence_strings = vec, n = 2L, cutoff = 0.6)
}
}
if (reticulate::py_available(initialize = FALSE)) {
if (check_availability()) {
library(fuzzywuzzyR)
vec = c('Frodo Baggins', 'Tom Sawyer', 'Bilbo Baggin')
str1 = 'Fra Bagg'
GetCloseMatches(string = str1, sequence_strings = vec, n = 2L, cutoff = 0.6)
}
}
GetCloseMatches(string = str1, sequence_strings = vec, n = 2L, cutoff = 0.6)
if (reticulate::py_available(initialize = FALSE)) {
if (check_availability()) {
library(fuzzywuzzyR)
vec = c('Frodo Baggins', 'Tom Sawyer', 'Bilbo Baggin')
str1 = 'Fra Bagg'
GetCloseMatches(string = str1, sequence_strings = vec, n = 2L, cutoff = 0.6)
}
else {
print("I am list")
}
}
if (reticulate::py_available(initialize = FALSE)) {
if (check_availability()) {
library(fuzzywuzzyR)
vec = c('Frodo Baggins', 'Tom Sawyer', 'Bilbo Baggin')
str1 = 'Fra Bagg'
GetCloseMatches(string = str1, sequence_strings = vec, n = 2L, cutoff = 0.6)
}
else {
print("I am list")
}
}
print("I am list")
if (reticulate::py_available(initialize = FALSE)) {
if (check_availability()) {
library(fuzzywuzzyR)
vec = c('Frodo Baggins', 'Tom Sawyer', 'Bilbo Baggin')
str1 = 'Fra Bagg'
GetCloseMatches(string = str1, sequence_strings = vec, n = 2L, cutoff = 0.6)
}
else {
print("I am list")
}
}
print("I am list")
GetCloseMatches("laZ", c("1 lazy", "1", "1 LAZY"),1L,0.7)
library(RMariaDB)
library(DBI)
library(bcputility)
#DB Set up
con <- dbConnect(RMariaDB::MariaDB(), username="root", password="TestCase123.", dbname ="basic", host="localhost")
dbListTables(con)
upload_data <- function(file_name) {
if (dbExistsTable(con, file_name))
dbRemoveTable(con, file_name)
current_data <- read.csv(file = paste('Data_Sets/',file_name,'.csv', sep = ""), header=TRUE)
dbWriteTable(con, name = file_name, value = current_data, row.names = FALSE)
dbListTables(con)
}
upload_data("data_science_job_posting")
current_data <- read.csv(file = paste('Data_Sets/','Cleaned_DS_Jobs','.csv', sep = ""), header=TRUE)
upload_data("Cleaned_DS_Jobs")
upload_data("listings2019_2022")
upload_data("Glassdoor USA Dataset")
