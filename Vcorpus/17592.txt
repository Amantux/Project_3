Responsibilities:
Responsible for building and maintaining the machine learning data and development platform.
Build, integrate and deploy machine learning solutions into the BlackLine application in collaboration with product management, cloud, engineering and data science teams.
Create and maintain scalable data pipeline in the cloud (AWS and GCP).
Assemble large, complex data sets that meet functional / non-functional business requirements.
Identify, design, and implement processes automation and data delivery.
Build infrastructure for optimal extraction, transformation, and loading of data from a wide variety of data sources.
Execute extract, transform and load (ETL) operations on large datasets including data identification, mapping, aggregation, conditioning, cleansing, and analyzing.
Build analytics tools to provide actionable insights into business and product performance.
Keep data separated, isolated and secured.
Assist data scientists in implementing achine learning algorithms and contribute to building and optimizing our product into an innovative industry leader.
Participate in establishing best practices while team is transitioning to new technologies, tools and infrastructure. Maintain specifications and metadata; follow the best practices.
Recommend and implement process improvements.
Maintain specifications and metadata; follow and develop best practices.
Coach and technically train data analysts, if needed.
Qualifications:
5+ years as a data engineer.
Experience with SQL, Python, R languages.
ETL experience using Python.
Experience with Hadoop, Spark, Hive. Presto is a plus.
Practical experience with GIT version control.
Strong familiarity with GCP, AWS, SQL Server.
Comfortable working with open source tools in Unix/Linux environments.
Data warehousing experience, data modeling and database design.
Experience with machine learning packages and various ML algorithms.
Experience with predictive and prescriptive analytics, modeling, and segmentation.
Experience with data analytics, big data, and analytics architectures.
Comfortable handling large amounts of data.
Experience ensuring data and modeling accuracy, cleanliness, reliability.
Works independently without the need for supervision.
Experience translating business requirements into functional, and non-functional requirements.
Strong sense systems and data ownership.
