(6 - 12) Months Contract.

Requirements:
5+ years of data engineering experience
Proficiency with REST APIs, Cassandra, Python, MongoDB, Postgres, and querying.
Proficiency with both relational and non-relational databases and how to combine them
Proficiency with distributed computing engines,frameworks like Hadoop v2, Spark
Responsibilities:
Experience with building stream-processing systems, (e.g., using solutions such as Spark-
Streaming or Storm)
Ability to manage Hadoop/Spark cluster or other ingestion tools, with all included services
Previous Experience with various messaging systems, such as Kafka or Amazon Kinesis(
for example)
Coding Experience with any of the programming languages - Python,Java, Scala
Powered by JazzHR
