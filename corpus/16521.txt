When you come across a sea of data, is your first instinct to put on your software diving suit and go deep? We’re looking for highly-skilled Data Engineers to design and automate large scale data solutions that power our state-of-the-art artificial intelligence platform. If “changing the world” is on your to-do list, Entefy is your chance to make a career of it.

We’re redefining digital interaction, and our next Data Engineer will play a key role in the growing agile team that’s making it all happen.
Requirements
6+ years relevant experience developing and integrating frameworks and database technologies that support highly scalable data processing
Advanced knowledge of system architecture and database design
Proficiency in Big Data tools: Spark, Hadoop, Kafka, etc.
Advanced experience with SQL and NoSQL database architecture and implementation (hands-on experience with PostgreSQL, Elasticsearch, and Cassandra a plus)
Demonstrable experience designing, developing, and implementing ETL processes
Experience working with private cloud infrastructure
Demonstrable experience building and optimizing Big Data pipelines and architecture
Proficiency in Python, Java, C++
Demonstrable experience with Stream Processing and workload management for data transformation, augmentation, analysis, etc.
Ability to collaborate well with others
Strong communication skills
Visit www.entefy.com and www.blog.entefy.com
