Job Description
Tiger Analytics is a fast-growing advanced analytics consulting firm. Our consultants bring deep expertise in Data Science, Machine Learning and AI. We are the trusted analytics partner for several Fortune 100 companies, enabling them to generate business value from data. Our business value and leadership has been recognized by various market research firms, including Forrester and Gartner.

We are looking for top-notch talent as we continue to build the best analytics global consulting team in the world.We are looking for talented individuals to join our team in building the core components of our software platforms use machine learning and artificial intelligence. In this role, we are seeking an experienced Data Engineer. The ideal candidate needs to be passionate about their work not just in words, but in demonstrable actions, both contributing and leading development of select aspects of our platforms and solutions. Successful candidates for this position must have experience designing and building production-level data pipelines. The candidate should be able to :
Create / enhance data pipelines, including the creation, enhancement and automation of advanced ETL flows and processes.
Collaborate in the design, development, test and maintenance of scalable data management solutions.
Assist other teams with data analysis (i.e. feature extraction) where appropriate and applicable.
Provide commercial quality software processes in a professional and timely manner.
Author clear technical documentation.
Accurately scope work and perform to agreed times lines.
Requirements
3+ years of experience with Python Programming Language.
Bachelors Degree in Computer Science or related field.
Hands-on experience in data modeling.
Develop applications and services that run on a cloud infrastructure (Private and Public).
Experience working in a Linux/Unix environment. Note that the majority of the work will be within the Azure infrastructure.
Knowledge and experience in ETL tools and automating data processing workflows.
Good level of understanding of data warehousing, business intelligence, and application data integration solutions.
Working knowledge of Apache Spark.
Knowledge of Azure Databricks.
Ability to thrive in a fast-paced, ever changing environment.
Excellent problem-solving skills and troubleshooting issues in a large, complex environment.
Experience with container management and deployment, such as Docker and Kubernetes.
Experience in data wrangling software as an analyst.
Excellent communication skills, both verbal and written. This includes the ability to write technical documentation, user guides, etc. as appropriate
Benefits

Significant career development opportunities exist as the company grows. The position offers a unique opportunity to be part of a small, challenging, and entrepreneurial environment, with a high degree of individual responsibility.
