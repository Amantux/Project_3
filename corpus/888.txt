job summary:

  Roles & Responsibilities:    

•Partner with senior business sponsors, platform supervision, compliance, and business management to develop a highly visible holistic supervisory and surveillance platform
•Design and implement a data strategy to support business use cases focused on multi-vector analysis using various natural language processing and machine learning techniques
•Primary focus is to analyze available structured and un-structured information, apply data mining techniques, perform statistical analysis, and provide methods (algorithmic and technical) to create actionable alerts and reduce false-positives
•Develop and enhance software solutions to meet business requirements
•Gather and document technical requirements and specifications
•Attend regular meetings and interface with internal and external teams related to the project
•Work with the project PM and BA's to provide input on schedules and implementation best practices
•Work on multiple tasks and respect aggressive schedule
•Work in a fast paced environment. Support may include extra hours, nights and weekends.
 
  Minimum required qualifications   

•Master's degree in engineering, math, statistics, physics or other technical field
•Experience with Big Data technologies including large data stores like Hadoop, Elastic, Apache Solr, et cetera
•Proven track record of implementing internal and/or external Big Data solutions
•Proven ability to find hidden insights and patterns within historical data
•Knowledge of various Statistical Analysis, Probabilistic Analysis and Data Visualization techniques preferred
•Experienced with Machine Learning
•Advanced knowledge of SQL systems, with at least 5 years experience developing in Oracle, Microsoft SQL Server, PostgreSQL, MySQL
•Advanced knowledge of NoSQL systems such as Cassandra, CouchDB, MongoDB, HBase, MarkLogic, Neo4J, Redis, and others
•Knowledge of Cloud Computing (AWS, Azure, Google)
•Knowledge of JAVA, J2EE, JavaScript, JSON, Python, Perl, SQL, and PL/SQL a plus
•Basic understanding of project lifecycle stages - Requirements Gathering to Post Implementation
•Experience in Architecting, designing, developing solutions using the ELK (Elasticsearch, Logstash and Kibana) stack.
•Worked on configuring ELK stack and used it for analyzing the logs from different applications.
•Ability to perform data related benchmarking, performance analysis and tuning.
•Strong skills in In-memory applications, Database design, Data integration.
•Experienced as a team player working in a global team
•Ability to manage conflicting requests on time in a continually fast moving environment
•Must be a self-starter with attention to detail
•Strong communications (written and oral) skills in a front-office setting
 
  Preferred qualifications:    

•Experience with Front Office traders, IT support and Operation teams in a Capital Markets domain.
•Knowledge of Actimize Trade Surveillance / Blotters, HP Autonomy, ElasticSearch, Python
•Experience with machine learning, natural language processing, AI, or robotics is a plus
  
location: New York, New York
job type: Contract
salary: $85 - 100  per hour
work hours: 9am to 5pm
education: Masters
 
responsibilities:

  Roles & Responsibilities:    

•Partner with senior business sponsors, platform supervision, compliance, and business management to develop a highly visible holistic supervisory and surveillance platform
•Design and implement a data strategy to support business use cases focused on multi-vector analysis using various natural language processing and machine learning techniques
•Primary focus is to analyze available structured and un-structured information, apply data mining techniques, perform statistical analysis, and provide methods (algorithmic and technical) to create actionable alerts and reduce false-positives
•Develop and enhance software solutions to meet business requirements
•Gather and document technical requirements and specifications
•Attend regular meetings and interface with internal and external teams related to the project
•Work with the project PM and BA's to provide input on schedules and implementation best practices
•Work on multiple tasks and respect aggressive schedule
•Work in a fast paced environment. Support may include extra hours, nights and weekends.
 
  Minimum required qualifications   

•Master's degree in engineering, math, statistics, physics or other technical field
•Experience with Big Data technologies including large data stores like Hadoop, Elastic, Apache Solr, et cetera
•Proven track record of implementing internal and/or external Big Data solutions
•Proven ability to find hidden insights and patterns within historical data
•Knowledge of various Statistical Analysis, Probabilistic Analysis and Data Visualization techniques preferred
•Experienced with Machine Learning
•Advanced knowledge of SQL systems, with at least 5 years experience developing in Oracle, Microsoft SQL Server, PostgreSQL, MySQL
•Advanced knowledge of NoSQL systems such as Cassandra, CouchDB, MongoDB, HBase, MarkLogic, Neo4J, Redis, and others
•Knowledge of Cloud Computing (AWS, Azure, Google)
•Knowledge of JAVA, J2EE, JavaScript, JSON, Python, Perl, SQL, and PL/SQL a plus
•Basic understanding of project lifecycle stages - Requirements Gathering to Post Implementation
•Experience in Architecting, designing, developing solutions using the ELK (Elasticsearch, Logstash and Kibana) stack.
•Worked on configuring ELK stack and used it for analyzing the logs from different applications.
•Ability to perform data related benchmarking, performance analysis and tuning.
•Strong skills in In-memory applications, Database design, Data integration.
•Experienced as a team player working in a global team
•Ability to manage conflicting requests on time in a continually fast moving environment
•Must be a self-starter with attention to detail
•Strong communications (written and oral) skills in a front-office setting
 
  Preferred qualifications:    

•Experience with Front Office traders, IT support and Operation teams in a Capital Markets domain.
•Knowledge of Actimize Trade Surveillance / Blotters, HP Autonomy, ElasticSearch, Python
•Experience with machine learning, natural language processing, AI, or robotics is a plus
  
qualifications:

  Roles & Responsibilities:    

•Partner with senior business sponsors, platform supervision, compliance, and business management to develop a highly visible holistic supervisory and surveillance platform
•Design and implement a data strategy to support business use cases focused on multi-vector analysis using various natural language processing and machine learning techniques
•Primary focus is to analyze available structured and un-structured information, apply data mining techniques, perform statistical analysis, and provide methods (algorithmic and technical) to create actionable alerts and reduce false-positives
•Develop and enhance software solutions to meet business requirements
•Gather and document technical requirements and specifications
•Attend regular meetings and interface with internal and external teams related to the project
•Work with the project PM and BA's to provide input on schedules and implementation best practices
•Work on multiple tasks and respect aggressive schedule
•Work in a fast paced environment. Support may include extra hours, nights and weekends.
 
  Minimum required qualifications   

•Master's degree in engineering, math, statistics, physics or other technical field
•Experience with Big Data technologies including large data stores like Hadoop, Elastic, Apache Solr, et cetera
•Proven track record of implementing internal and/or external Big Data solutions
•Proven ability to find hidden insights and patterns within historical data
•Knowledge of various Statistical Analysis, Probabilistic Analysis and Data Visualization techniques preferred
•Experienced with Machine Learning
•Advanced knowledge of SQL systems, with at least 5 years experience developing in Oracle, Microsoft SQL Server, PostgreSQL, MySQL
•Advanced knowledge of NoSQL systems such as Cassandra, CouchDB, MongoDB, HBase, MarkLogic, Neo4J, Redis, and others
•Knowledge of Cloud Computing (AWS, Azure, Google)
•Knowledge of JAVA, J2EE, JavaScript, JSON, Python, Perl, SQL, and PL/SQL a plus
•Basic understanding of project lifecycle stages - Requirements Gathering to Post Implementation
•Experience in Architecting, designing, developing solutions using the ELK (Elasticsearch, Logstash and Kibana) stack.
•Worked on configuring ELK stack and used it for analyzing the logs from different applications.
•Ability to perform data related benchmarking, performance analysis and tuning.
•Strong skills in In-memory applications, Database design, Data integration.
•Experienced as a team player working in a global team
•Ability to manage conflicting requests on time in a continually fast moving environment
•Must be a self-starter with attention to detail
•Strong communications (written and oral) skills in a front-office setting
 
  Preferred qualifications:    

•Experience with Front Office traders, IT support and Operation teams in a Capital Markets domain.
•Knowledge of Actimize Trade Surveillance / Blotters, HP Autonomy, ElasticSearch, Python
•Experience with machine learning, natural language processing, AI, or robotics is a plus
  
skills:    Roles & Responsibilities:   


•Partner with senior business sponsors, platform supervision, compliance, and business management to develop a highly visible holistic supervisory and surveillance platform
•Design and implement a data strategy to support business use cases focused on multi-vector analysis using various natural language processing and machine learning techniques
•Primary focus is to analyze available structured and un-structured information, apply data mining techniques, perform statistical analysis, and provide methods (algorithmic and technical) to create actionable alerts and reduce false-positives
•Develop and enhance software solutions to meet business requirements
•Gather and document technical requirements and specifications
•Attend regular meetings and interface with internal and external teams related to the project
•Work with the project PM and BA's to provide input on schedules and implementation best practices
•Work on multiple tasks and respect aggressive schedule
•Work in a fast paced environment. Support may include extra hours, nights and weekends.
 
  Minimum required qualifications   

•Master's degree in engineering, math, statistics, physics or other technical field
•Experience with Big Data technologies including large data stores like Hadoop, Elastic, Apache Solr, et cetera
•Proven track record of implementing internal and/or external Big Data solutions
•Proven ability to find hidden insights and patterns within historical data
•Knowledge of various Statistical Analysis, Probabilistic Analysis and Data Visualization techniques preferred
•Experienced with Machine Learning
•Advanced knowledge of SQL systems, with at least 5 years experience developing in Oracle, Microsoft SQL Server, PostgreSQL, MySQL
•Advanced knowledge of NoSQL systems such as Cassandra, CouchDB, MongoDB, HBase, MarkLogic, Neo4J, Redis, and others
•Knowledge of Cloud Computing (AWS, Azure, Google)
•Knowledge of JAVA, J2EE, JavaScript, JSON, Python, Perl, SQL, and PL/SQL a plus
•Basic understanding of project lifecycle stages - Requirements Gathering to Post Implementation
•Experience in Architecting, designing, developing solutions using the ELK (Elasticsearch, Logstash and Kibana) stack.
•Worked on configuring ELK stack and used it for analyzing the logs from different applications.
•Ability to perform data related benchmarking, performance analysis and tuning.
•Strong skills in In-memory applications, Database design, Data integration.
•Experienced as a team player working in a global team
•Ability to manage conflicting requests on time in a continually fast moving environment
•Must be a self-starter with attention to detail
•Strong communications (written and oral) skills in a front-office setting
 
  Preferred qualifications:    

•Experience with Front Office traders, IT support and Operation teams in a Capital Markets domain.
•Knowledge of Actimize Trade Surveillance / Blotters, HP Autonomy, ElasticSearch, Python
•Experience with machine learning, natural language processing, AI, or robotics is a plus
 
Equal Opportunity Employer: Race, Color, Religion, Sex, Sexual Orientation, Gender Identity, National Origin, Age, Genetic Information, Disability, Protected Veteran Status, or any other legally protected group status.  
      

Job Summary

                 
                     
                         Location 
                             New York, NY 10019 
                     
                 
                             
                     
                         Job type 
                         Full Time, Temporary/Contract/Project 
                     
                 
                 
                     
                         Posted 
                         Today 
                     
                 
                 
                     
                         Industries 
                         Computer Hardware; Computer Software; Computer/IT Services 
                     
                 
                 
                     
                         Career level 
                         Experienced (Non-Manager) 
                     
                 
                             
                     
                         Reference code 
                         704415
