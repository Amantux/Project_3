Duties: You will leverage your technical knowledge and experience to help design data ingestion and data preparation patterns which are reusable within and across teams Daily you will be working a variety of tasks (analysis, development, DevOps) with a variety of technologies (Python, Airflow, AWS and many more) You will be collaborating with squad resources in an agile framework to ensure work is planned and completed in the sprint cycle Job Requirements Requirements: Snowflake Experience is a MUST Advanced experience with Python and SQL is required. Experience building DAGs with Apache Airflow is a plus. 3+ years of hands-on experience developing large-volume applications with various types of database systems: relational (Oracle, Postgres, MySQL, MSSQL) required, and knowledge of Snowflake is a plus. Experience with Linux environments, ability to interface with the OS using system tools, scripting languages, integration frameworks, etc. Experience with DevOps, Continuous Integration and Continuous Delivery (Maven, Jenkins, Stash, Docker). Experience and comfort executing projects in Agile environments. Excellent verbal and written communication skills.
