At American Family Insurance, we’re driven by our customers and employees. That’s why we provide more than just a job – we provide opportunity. Whether you’re already part of our team in search of a new challenge or new to our company and ready for what’s next, you’re in the right place. Every dream is a journey that starts with a single step. Start your journey right here. Join our team. Bring your dreams.

Job ID:
R15759 Senior Big Data Engineer (Open)
Summary:
Job Family Summary

Determines and builds the technical solution(s) to allow unstructured data to be structured and used by Data Scientists. Seeks to understand the data being worked with as its often unstructured data sets. Often are data gurus who prepare data for all stages of the modeling process including exploration, training, testing, and deployment.

Job Summary Wording

As a Data Engineer, you’ll work on collecting, storing, processing and building Business Intelligence and Analytics applications within our big data platform. Presently, our team is constructing an enterprise data lake to enable analysts and scientists to self-service data at scale across American Family’s operating companies. We’re leveraging open source technologies like Spark, Python, Hadoop, and cloud native tools to curate high-quality data sets. You’ll also be responsible for integrating these applications with the architecture used across the organization. Adjacent responsibilities include establishing best practices with respect to data integration, data visualization, schema design, performance and reliability of data processing systems, supporting data quality, and enabling convenient access to data for our scientists and business users.

Job Description:


Job Level Summary
Requires working knowledge and experience in own job discipline and broadens capabilities
Continues to build knowledge of the company, processes and customers
Performs a range of assignments related to job discipline
Uses prescribed guidelines or policies in analyzing situations
Receives a moderate level of guidance and direction
Primary Accountabilities
Perform exploratory data analysis to determine which questions can be answered effectively with a given dataset.
Develop highly scalable and extensible data pipelines from internal and external sources.
Work on cross-functional teams to develop and deploy data-driven applications and products, particularly within the space of data science.
Assist with prototyping emerging technologies involving data ingestion and transformation, distributed file systems, databases and frameworks.
Build and maintain tools to increase the productivity of application development and client facing teams.
Develop and automate data quality checks.
Develop big data applications and data visualization tools.
Travel Requirements
This position requires travel up to 10% of the time.
Education and Licenses
Bachelor’s degree in computer science or related field, or equivalent combination of education and experience.
Specialized Knowledge & Skills Requirements
Demonstrated experience providing customer-driven solutions, support or service.
Knowledge of SQL and experience using a variety of data stores (e.g. RDBMS, analytic database, scalable document stores).
Hands-on programming experience in Python or java, with an emphasis towards building ETL workflows and data-driven solutions.
Working familiarity with Linux scripting to automate workflows.
Understanding of database internals, such as indexes, binary logging, and transactions.
Knowledge of cloud computing platforms (e.g. AWS, GCP, Azure).
Understanding of Infrastructure as Code (e.g. Docker, CloudFormation, Terraform, etc.)
Additional Job Information:
Top candidates will have 5-10 years of post-academic data engineering experience. This is not a Business Intelligence role nor an ETL Developer.Depending on qualifications, candidates may be hired at a different levels.We are seeking candidates with demonstrated experience using Python and SQL--a coding challenge will be incorporate into the selection process.Knowledge and experience of cloud platforms a plus, specifically AWS.Candidates experience with Python, AWS, and/or Hadoop preferred.

Offer to selected candidate will be made contingent on the results of applicable background checks.

Offer to selected candidate is contingent on signing a non-disclosure agreement for proprietary information, trade secrets, and inventions.

Relocation assistance is available.

Stay connected: Join our Talent Community!

LI:DB1

At American Family Insurance, we’re driven by our customers and employees. That’s why we provide more than just a job – we provide opportunity. Whether you’re already part of our team in search of a new challenge or new to our company and ready for what’s next, you’re in the right place. Every dream is a journey that starts with a single step. Start your journey right here. Join our team. Bring your dreams.

Job ID:
R15759 Senior Big Data Engineer (Open)
Summary:
Job Family Summary

Determines and builds the technical solution(s) to allow unstructured data to be structured and used by Data Scientists. Seeks to understand the data being worked with as its often unstructured data sets. Often are data gurus who prepare data for all stages of the modeling process including exploration, training, testing, and deployment.

Job Summary Wording

As a Data Engineer, you’ll work on collecting, storing, processing and building Business Intelligence and Analytics applications within our big data platform. Presently, our team is constructing an enterprise data lake to enable analysts and scientists to self-service data at scale across American Family’s operating companies. We’re leveraging open source technologies like Spark, Python, Hadoop, and cloud native tools to curate high-quality data sets. You’ll also be responsible for integrating these applications with the architecture used across the organization. Adjacent responsibilities include establishing best practices with respect to data integration, data visualization, schema design, performance and reliability of data processing systems, supporting data quality, and enabling convenient access to data for our scientists and business users.

Job Description:


Job Level Summary
Requires working knowledge and experience in own job discipline and broadens capabilities
Continues to build knowledge of the company, processes and customers
Performs a range of assignments related to job discipline
Uses prescribed guidelines or policies in analyzing situations
Receives a moderate level of guidance and direction
Primary Accountabilities
Perform exploratory data analysis to determine which questions can be answered effectively with a given dataset.
Develop highly scalable and extensible data pipelines from internal and external sources.
Work on cross-functional teams to develop and deploy data-driven applications and products, particularly within the space of data science.
Assist with prototyping emerging technologies involving data ingestion and transformation, distributed file systems, databases and frameworks.
Build and maintain tools to increase the productivity of application development and client facing teams.
Develop and automate data quality checks.
Develop big data applications and data visualization tools.
Travel Requirements
This position requires travel up to 10% of the time.
Education and Licenses
Bachelor’s degree in computer science or related field, or equivalent combination of education and experience.
Specialized Knowledge & Skills Requirements
Demonstrated experience providing customer-driven solutions, support or service.
Knowledge of SQL and experience using a variety of data stores (e.g. RDBMS, analytic database, scalable document stores).
Hands-on programming experience in Python or java, with an emphasis towards building ETL workflows and data-driven solutions.
Working familiarity with Linux scripting to automate workflows.
Understanding of database internals, such as indexes, binary logging, and transactions.
Knowledge of cloud computing platforms (e.g. AWS, GCP, Azure).
Understanding of Infrastructure as Code (e.g. Docker, CloudFormation, Terraform, etc.)
Additional Job Information:
Top candidates will have 5-10 years of post-academic data engineering experience. This is not a Business Intelligence role nor an ETL Developer.Depending on qualifications, candidates may be hired at a different levels.We are seeking candidates with demonstrated experience using Python and SQL--a coding challenge will be incorporate into the selection process.Knowledge and experience of cloud platforms a plus, specifically AWS.Candidates experience with Python, AWS, and/or Hadoop preferred.

Offer to selected candidate will be made contingent on the results of applicable background checks.

Offer to selected candidate is contingent on signing a non-disclosure agreement for proprietary information, trade secrets, and inventions.

Relocation assistance is available.

Stay connected: Join our Talent Community!

LI:DB1
