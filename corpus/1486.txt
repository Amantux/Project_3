Minimum Requirements Experience developing Data Pipelines for Data Ingestion or Transformation using Java or Scala or Python Experience in the following Big Data frameworks File Format (Parquet, AVRO, ORC etc..) Developing applications with Monitoring, Build Tools, Version Control, Unit Test, TDD, Change Management to support DevOps Experience with SQL and Shell Scripting experience Experience with the Apache Spark Spark Professional work experience in Big Data development Data warehousing ETL design, development and implementation experience Python or Java development experience
