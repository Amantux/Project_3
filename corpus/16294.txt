Minimum 12 years of IT experience in building data lake in Hadoop ecosystem.
Hands on experience in design and development of ingestion framework, Data quality , Audit Balancing and Egress framework using Hive/Spark .
Good working knowledge in Hdfs, Hive, Spark, Sqoop, Unix technology
Experience on Hive/Spark and data pipeline creation with Unix knowledge. Writing highly standard HQL and identifying performance bottleneck.
Hands on with loading and manipulating large data sets using Hive & SparkSQL.
Knowledge on performance optimization, debugging and troubleshooting Hadoop jobs. Preparing unit test cases and ensure defect free code delivery.
Prior project experience on Agile methodology and DevOps technology. Good understanding of project management tools such as JIRA, GitHub etc.
Good knowledge on Health Insure Domain( Specifically PAYER Industry is added advantage).
Very good communication and customer interaction skills.
Experience in onsite/offshore delivery model.

Job Types: Full-time, Contract

Schedule:
Monday to Friday
Work Remotely:
Temporarily due to COVID-19
