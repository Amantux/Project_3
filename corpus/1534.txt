The Data & Analytics Engineering organization of Liberty Mutual GRM is expanding its data modeling team. Data Modelers design transactional and analytical databases that translate complex business data into usable computer systems. Data Modelers work with data architects to design databases and data structures that meet organizational needs using conceptual, logical, and physical data models. Their models are designed to improve efficiency and business value and may focus on issues such as reducing data redundancy, improving data quality or improving data movement across systems.

An ideal Data Modeler is an analytical and creative thinker who is not intimidated by roadblocks and challenges. They understand how to successfully evaluate problems and develop appropriate solutions. Data Modelers perform well under pressure, possessing great focus while completing projects efficiently. They should be able to work well as part of a team, but also carry responsibility for their own work. Data Modelers also need to be able to work on multiple projects at a time, with the ability to quickly understand and incorporate new technologies. Below are the skills and abilities that Information Management will look for in a Data Modeler.
What you will do:
Work with the Data Office, Data & Analytics Engineering and Application Development teams to translate business needs into data solutions
Create and Maintain Conceptual, Logical and Physical Data Models
Support Agile squads with creation of DDL and table creation
Participate in Data Governance procedures and policy management
Mentor, contribute and govern Data Management standards and best practices
What you will need:
Bachelor's degree in Computer Science or similar
Previous experience translating Business rules into Conceptual, Logical & Physical models for OLTP / OLAP / Graph / NoSQL databases
Familiarity with Data Warehouse modeling techniques like Data Vault 2.0 and Dimensional
5+ years experience with DBMS (MySQL, SQL Server, Postgres, Oracle, Teradata, Snowflake, DB2)
3+ years experience with cloud-based Data Warehouse and Data Lake environments
Software Development experience with SQL and preferably Python or JavaScript
Experience in converting relational data models to semi-structured data (XML, JSON) or vice versa
5+ years experience with modeling tools such as Erwin or ER/Studio
Must be able to work independently and collaboratively on large scale data projects
Experience in these areas is a Plus:
Experience with ETL tools such as Informatica or Snaplogic
Experience with MDM solutions
Exposure to Business Intelligence tools (PowerBI, MicroStrategy)
Exposure with messaging solution like Kafka and MQ
Has worked with industry standard canonical models
Experience in Enterprise reference and master data management strategies
